{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### only colab\n",
    "# ! git clone 'https://github.com/kangjun205/Dacon_AuthorClassification.git'\n",
    "# %cd Dacon_AuthorClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "from wandb.apis import public\n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# ## only local\n",
    "# sys.path.append('..')\n",
    "\n",
    "from utils.clean import clean_texts\n",
    "\n",
    "from src.model import BertForMultiLabelClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test_x.csv') ## text for test\n",
    "sample_submission = pd.read_csv('sample_submission.csv') ## submission file form\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model hyperparameter loading\n",
    "api = public.Api()\n",
    "run_path = 'kangjun205/Dacon_AuthorClassification/run-id'  # run-id 수정\n",
    "run = api.run(run_path)\n",
    "params = run.config\n",
    "\n",
    "## model state loading\n",
    "model_file = run.file('bert_0412.pt').download(replace = True).name\n",
    "model = BertForMultiLabelClassification(params['NUM_LABELS'], params['NUM_HIDDEN'])\n",
    "model.load_state_dict(torch.load(model_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cleaning\n",
    "test_data = clean_texts(test['text'])\n",
    "\n",
    "## tokenization\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') ## tokenizer 호출\n",
    "encoding = tokenizer.encode_plus(\n",
    "    test_data,\n",
    "    add_special_tokens=True,\n",
    "    max_length=params['MAX_LEN'],\n",
    "    return_token_type_ids=False,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    return_attention_mask=True,\n",
    "    return_tensors='pt',\n",
    ")\n",
    "input_ids = encoding['input_ids'].flatten()\n",
    "attention_mask = encoding['attention_mask'].flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction & Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## device 설정\n",
    "model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "input_ids.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "attention_mask.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "## prediction\n",
    "model.eval()\n",
    "with torh.no_grad() :\n",
    "    predicted_values = model(input_ids, attention_mask).to('cpu')\n",
    "    predicted_values = pd.DataFrame(predicted_values.detach().numpy())\n",
    "\n",
    "## submission file generation\n",
    "sample_submission[['0', '1', '2', '3', '4']] = predicted_values\n",
    "sample_submission.to_csv('submission.csv', index = False, encoding = 'utf-8')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
